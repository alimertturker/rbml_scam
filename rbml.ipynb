{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90bdc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numpy import linalg as LA\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eab863c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBML:\n",
    "    def __init__(self, x, y, k=3, alpha=0.5, beta=2.):\n",
    "        self.x = x\n",
    "        self.len_ = len(x)\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.labels = np.unique(self.y)\n",
    "        self.neigh = NearestNeighbors(n_neighbors=4)\n",
    "        self.neigh.fit(self.x)\n",
    "        \n",
    "    def find_target_neighbors(self, i):\n",
    "        neighbors = self.neigh.kneighbors(self.x[i].reshape(1, -1), self.len_, return_distance=False)[:,1:][0]\n",
    "        target_neighbors = []\n",
    "        label = y[i]\n",
    "        count_ = 0\n",
    "        l = 0\n",
    "        while count_ != self.k and l < self.len_-1:\n",
    "            if self.y[neighbors[l]] == label:\n",
    "                target_neighbors.append(neighbors[l])\n",
    "                count_+=1\n",
    "            l+=1\n",
    "        return target_neighbors    \n",
    "    \n",
    "    def find_imposters(self, i):\n",
    "        neighbors = self.neigh.kneighbors(self.x[i].reshape(1, -1), self.len_, return_distance=False)[:,1:][0]\n",
    "        imposters = []\n",
    "        label = y[i]\n",
    "        k = 0\n",
    "        while k < self.len_-1:\n",
    "            if self.y[neighbors[k]] != label:\n",
    "                imposters.append(neighbors[k])\n",
    "            k+=1\n",
    "        return imposters\n",
    "    \n",
    "    def delta_t(self, i, j):\n",
    "        neighbors = self.find_target_neighbors(i)\n",
    "        return 1 if j in neighbors else 0\n",
    "    \n",
    "    def Tv(self, i):\n",
    "        sum_ = 0\n",
    "        for j in range(self.len_):\n",
    "            sum_ += (LA.norm(x[i] - x[j])**2)*self.delta_t(i, j)\n",
    "        return sum_\n",
    "    \n",
    "    def TX(self):\n",
    "        sum_ = 0\n",
    "        for i in tqdm(range(self.len_)):\n",
    "            sum_ += self.Tv(i)\n",
    "        return sum_\n",
    "    \n",
    "    def m(self, i):\n",
    "        neighbors = self.find_target_neighbors(i)\n",
    "        #Â neighbors[-1] most distant target neighbor\n",
    "        mi = self.beta*(LA.norm(x[i] - self.x[neighbors[-1]])**2)*self.delta_t(i, neighbors[-1])\n",
    "        return mi\n",
    "    \n",
    "    def delta_i(self, i, j):\n",
    "        #print(\"la\",LA.norm(x[i] - x[j])**2)\n",
    "        #print(\"mi\",self.m(i))\n",
    "        t1 = (LA.norm(x[i] - x[j])**2 < self.m(i))\n",
    "        t2 = (y[i] != y[j])\n",
    "        return 1 if t1 and t2 else 0\n",
    "    \n",
    "    def Hv(self, i):\n",
    "        sum_ = 0\n",
    "        for j in range(self.len_):\n",
    "            sum_ += (self.m(i) - LA.norm(x[i] - x[j])**2)*self.delta_i(i,j)\n",
    "        return sum_\n",
    "    \n",
    "    def HX(self):\n",
    "        sum_ = 0\n",
    "        for i in tqdm(range(self.len_)):\n",
    "            sum_ += self.Hv(i)\n",
    "        return sum_\n",
    "    \n",
    "    def C(self):\n",
    "        return (1-self.alpha)*self.TX() + self.alpha*self.HX()\n",
    "    \n",
    "    def xiN(self, i):\n",
    "        sum_ = 0\n",
    "        sum_t = 0\n",
    "        for j in range(len(self.x)):\n",
    "            sum_ += self.x[j]*self.delta_t(i,j)\n",
    "            sum_t += self.delta_t(i,j)\n",
    "        \n",
    "        return sum_/sum_t if sum_t != 0 else 0\n",
    "    \n",
    "    def xjI(self, i):\n",
    "        sum_ = 0\n",
    "        sum_t = 0\n",
    "        for j in range(self.len_):\n",
    "            delta_value = self.delta_i(i,j)\n",
    "            sum_ += self.x[j]*delta_value\n",
    "            sum_t += delta_value\n",
    "        #  if sum_t != 0 else 0\n",
    "        return sum_/sum_t if sum_t != 0 else 0\n",
    "    \n",
    "    # Updated hinge loss\n",
    "    def Hv_(self, i):\n",
    "        return max(0, (self.m(i) - LA.norm(x[i] - self.xjI(i))**2))\n",
    "    \n",
    "    def xiH(self, i):\n",
    "        return self.x[i] + self.m(i)*((self.x[i]-self.xjI(i))/(LA.norm(x[i] - self.xjI(i))**2))  \n",
    "    \n",
    "    def xi_star(self, i):\n",
    "        return (1-self.alpha)*self.xiN(i) + self.alpha*self.xiH(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "033a5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method for Iris, Wine, Sonar datasets(a leave-one-out cross validation)\n",
    "def convergence_method(x, y, splitter, k=3):\n",
    "    accuracies = []\n",
    "    for train_index, test_index in splitter:\n",
    "        X_train, X_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "    accuracies = np.array(accuracies)\n",
    "    acc_mean = np.mean(accuracies)\n",
    "    return acc_mean\n",
    "\n",
    "# Build a K-NN classifier with X*'s (at first iteration with X's) then test the test dataset\n",
    "# This method for Balance, pima, vowel datasets(With train and test(250 sample) splits)\n",
    "def convergence_method_v2(X_train, y_train, X_test, y_test, k=3):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f23c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method for Iris, Wine, Sonar datasets(a leave-one-out cross validation)\n",
    "def rblm_process(x, y, splitter):\n",
    "    rbml_ = RBML(x, y)\n",
    "    flag = True\n",
    "    old_acc = convergence_method(x, y, splitter.split(x))\n",
    "\n",
    "    while flag:\n",
    "        print(f\"Accuracy before iteration = {old_acc}\")\n",
    "        x_stars = []\n",
    "        for i in tqdm(range(rbml_.len_)):\n",
    "            x_stars.append(rbml_.xi_star(i))\n",
    "        x_stars = np.array(x_stars)\n",
    "\n",
    "        rbml_.x = x_stars\n",
    "        new_acc = convergence_method(rbml_.x, rbml_.y, splitter.split(rbml_.x))\n",
    "        print(f\"Accuracy after iteration = {new_acc}\")\n",
    "        # Iteration will continue until it converges\n",
    "        # Converge conditions are accuracy will be 100% or accuracy won't increase from previous one \n",
    "        if new_acc <= old_acc or new_acc == 1:\n",
    "            flag = False\n",
    "        else:\n",
    "            old_acc = new_acc\n",
    "    return x_stars\n",
    "\n",
    "# This method for Balance, pima, vowel datasets(With train and test(250 sample) splits)\n",
    "def rblm_process_v2(X_train, y_train, X_test, y_test):\n",
    "    rbml_ = RBML(X_train, y_train)\n",
    "    flag = True\n",
    "    old_acc = convergence_method_v2(rbml_.x, rbml_.y, X_test, y_test)\n",
    "\n",
    "    while flag:\n",
    "        print(f\"Accuracy before iteration = {old_acc}\")\n",
    "        x_stars = []\n",
    "        # Find the x stars according to algorithm\n",
    "        for i in tqdm(range(rbml_.len_)):\n",
    "            x_stars.append(rbml_.xi_star(i))\n",
    "        x_stars = np.array(x_stars)\n",
    "\n",
    "        rbml_.x = x_stars\n",
    "        new_acc = convergence_method_v2(rbml_.x, rbml_.y, X_test, y_test)\n",
    "        \n",
    "        print(f\"Accuracy after iteration = {new_acc}\")\n",
    "        # Iteration will continue until it converges\n",
    "        # Converge conditions are accuracy will be 100% or accuracy won't increase from previous one \n",
    "        if new_acc <= old_acc or new_acc == 1:\n",
    "            flag = False\n",
    "        else:\n",
    "            old_acc = new_acc\n",
    "    return x_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "547fa7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_regressor(x, x_star):\n",
    "    regressionSets = []\n",
    "    predictors = []\n",
    "    arr_x = np.array(x)\n",
    "    arr_x_star = np.array(x_star)\n",
    "    arr_x[0]\n",
    "    featureSize = len(x[0])\n",
    "    for i in range(featureSize):\n",
    "        predictors.append(RandomForestRegressor(max_depth=2, random_state=0))\n",
    "        predictors[i].fit(arr_x,arr_x_star[:,i])\n",
    "    \n",
    "    return predictors\n",
    "\n",
    "def regression(predictor, x):\n",
    "    result = []\n",
    "    for i in range(len(x)):\n",
    "        val = predictor[i].predict([x])\n",
    "        result.append(val[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898a485",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e31b3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26eba2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"IRIS.csv\")\n",
    "x = data.iloc[:, [1, 2, 3, 4]].values\n",
    "y = data.iloc[:, [5]].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2de4c0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before iteration = 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 150/150 [01:05<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after iteration = 1.0\n"
     ]
    }
   ],
   "source": [
    "x_starts = rblm_process(x,y, loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "add94d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = init_regressor(x, x_starts)\n",
    "x_start_reg = []\n",
    "for x_ in x:\n",
    "    x_start_reg.append(regression(predictor, x_))\n",
    "\n",
    "convergence_method_v2(x_start_reg,y, x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610df03c",
   "metadata": {},
   "source": [
    "# Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e832ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf30957",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataset = load_wine()\n",
    "x = wine_dataset['data']\n",
    "y = wine_dataset['target'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stars = rblm_process(x,y,loo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8d62e",
   "metadata": {},
   "source": [
    "# Sonar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "b9eb0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sonar_csv.csv\")\n",
    "x = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "54afba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before iteration = 0.8894230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââ| 208/208 [01:28<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after iteration = 0.9711538461538461\n",
      "Accuracy before iteration = 0.9711538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââ| 208/208 [01:40<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after iteration = 0.9951923076923077\n",
      "Accuracy before iteration = 0.9951923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââ| 208/208 [01:26<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after iteration = 0.9951923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_stars = rblm_process(x,y,loo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05b2f7",
   "metadata": {},
   "source": [
    "# Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "7b26807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data =  pd.read_csv('balance-scale.data', sep=\",\")\n",
    "x = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "08a41478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data(250 test data according to paper)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "4a5c715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before iteration = 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââ| 374/374 [05:45<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after iteration = 0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_stars = rblm_process_v2(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9e924",
   "metadata": {},
   "source": [
    "# Pima Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c7a602ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "x = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "3e265715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data(250 test data according to paper)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3367c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stars = rblm_process_v2(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd528b2",
   "metadata": {},
   "source": [
    "# Vowel Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e4a7efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"vowel-context.data\", header=None, sep=' ')\n",
    "x = data.iloc[:, [3,4,5,6,7,8,9,10,11,12]].values\n",
    "y = data.iloc[:, 14].values.ravel()\n",
    "y = np.nan_to_num(y, nan=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "3a03b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data(250 test data according to paper)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24327675",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stars = rblm_process_v2(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
